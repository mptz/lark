/*
 * Copyright (c) 2009-2022 Michael P. Touloumtzis.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 */

#include <assert.h>

#include <util/memutil.h>
#include <util/message.h>

#include "crumble.h"
#include "node.h"
#include "term.h"

/*
 * In the SCAM machine definition, the variable '*' (a five-pointed
 * star in the original) is a special variable marking the start of a
 * linear environment of explicit substitution nodes.  In this code
 * base it corresponds to node->prev == NULL.
 */
#define STAR NULL

static struct node_and_prev {
	struct node *node, *prev;
} crumble_term(struct term *term, struct node *prev, unsigned depth);

/*
 * crumble_flatten is called twice when we're constructing an application
 * node, once to process the function and once for the argument.  We
 * eliminate nesting by returning a variable (bound, free, or subst); if
 * there's a nested term within the application, we attach that to the
 * linear environment we're constructing (attach it to 'prev').  We
 * return the slot to write to the application along with the current
 * head of the list.
 *
 * We always return variable bits for the LHS here, but the caller can
 * shift them for the RHS if we're being called for the RHS.
 */
static struct slot_and_prev {
	unsigned bits;
	union slot slot;
	struct node *prev;
} crumble_flatten(struct term *term, struct node *prev, unsigned depth)
{
	switch (term->variety) {
	case TERM_ABS:
	case TERM_APP: {
		struct node_and_prev nap = crumble_term(term, prev, depth);
		return (struct slot_and_prev) {
			.bits = NODE_LHS_SUBST,
			.slot.subst = nap.node,
			.prev = nap.prev,
		};
	}
	case TERM_BOUND_VAR:
		/*
		 * Since we only crumble top-level terms, bound variable
		 * indexes are bounded by the current abstraction depth.
		 * Outside any abstractions (depth == 0) we shouldn't
		 * encounter a bound variable at all.
		 */
		assert(term->bv.index < depth);
		return (struct slot_and_prev) {
			.bits = NODE_LHS_BOUND,
			.slot.index = term->bv.index,
			.prev = prev,
		};
	case TERM_FREE_VAR:
		return (struct slot_and_prev) {
			.bits = NODE_LHS_FREE,
			.slot.term = term,
			.prev = prev,
		};
	default:
		panicf("Unhandled term variety %d\n", term->variety);
	}
}

static struct node_and_prev
crumble_term(struct term *term, struct node *prev, unsigned depth)
{
	struct node_and_prev retval;

	switch (term->variety) {
	case TERM_ABS:
		retval.node = retval.prev =
			NodeAbs(prev, depth, term->abs.formal,
				crumble_term(term->abs.body,
					     STAR, depth + 1).prev);
		break;
	case TERM_APP: {
		retval.node = prev = NodeApp(prev, depth);
		struct slot_and_prev
			lhs = crumble_flatten(term->app.fun, prev, depth),
			rhs = crumble_flatten(term->app.arg, lhs.prev, depth);
		/*
		 * We only use SUBST slots when crumbling an application.
		 * When we do so, we set 'backref' in the referent to the
		 * referring slot.  Since non-star nodes generated by
		 * crumbling always have a reference count of 1, there's
		 * a unique referrer for each referent; this property will
		 * be lost as additional references accumulate during
		 * R-to-L traversal, but after we pass a node in R-to-L
		 * traversal we're done using its backreference anyway.
		 * 
		 *       +-----------+
		 *       |  +--------|-----------------+
		 *       |  |        |                 |
		 *       |  |        v                 v
		 * ... [(^X ^Y)] ... [@X, backref] ... [@Y, backref]
		 *        ^  ^               |                 |
		 *        |  |               |                 |
		 *	  +--|---------------+                 |
		 *	     +---------------------------------+
		 *
		 * We also set 'nref' in the referenced node to 1 to
		 * reflect the single application node referencing it.
		 */
		prev->lhs = lhs.slot;
		if (lhs.bits == NODE_LHS_SUBST) {
			assert(lhs.slot.subst != prev);
			assert(lhs.slot.subst->nref == 0);
			lhs.slot.subst->nref = 1;
			lhs.slot.subst->backref = &prev->lhs;
		}
		prev->rhs = rhs.slot;
		rhs.bits <<= NODE_LHS_RHS_SHIFT;
		if (rhs.bits == NODE_RHS_SUBST) {
			assert(rhs.slot.subst != prev);
			assert(rhs.slot.subst->nref == 0);
			rhs.slot.subst->nref = 1;
			rhs.slot.subst->backref = &prev->rhs;
		}
		prev->bits = lhs.bits | rhs.bits;
		retval.prev = rhs.prev;
		break;
	}
	case TERM_BOUND_VAR:
		/*
		 * As above, bound variable indexes should be strictly
		 * less than the number of abstractions traversed so far.
		 */
		assert(term->bv.index < depth);
		retval.node = retval.prev =
			NodeBoundVar(prev, depth, term->bv.index);
		break;
	case TERM_FREE_VAR:
		retval.node = retval.prev = NodeFreeVar(prev, depth, term);
		break;
	default:
		panicf("Unhandled term variety %d\n", term->variety);
	}
	return retval;
}

struct node *crumble(struct term *term)
{
	return crumble_term(term, STAR, 0).prev;
}

/*
 * Uncrumbling is the opposite of crumbling: reading back a tree from
 * the flattened lists of explicit substitutions.  This undoes sharing,
 * which can drastically expand some terms (exponentially, in the worst
 * case) but yields tractable expansion for most terms in practical use.
 *
 * For the most part, we can walk the tree of nested abstractions &
 * applications depth-first, following node pointers at every option,
 * and be fine.
 *
 * The main trick is correcting De Bruijn indexes of bound variables.
 * Sometimes a 'subst' slot points to a node at a lower abstraction
 * depth (i.e. in an outer scope relative to the current term),
 * requiring us to shift bound variable indexes in order to "pull"
 * the tree we're substituting in down to a greater abstraction depth.
 *
 * As is usual with such shifting, as we descend to greater
 * abstraction depths in the tree we're substituting (copying in),
 * we need to track the boundary between variables which were bound
 * in the tree being copied--as we have also copied their binders,
 * we don't need to adjust their indexes--and variables which were
 * free in the tree being copied, which must be shifted.  The 'cutoff'
 * variable, which increases as we enter abstractions, performs this
 * role.
 *
 * A slight complication is that our copies are nested--at any point
 * we can encounter a node which points upwards--so we build a linked
 * list of cutoffs and 'deltas' for shifting, allowing us to map a
 * bound variable back through all nested copies to the index it
 * should hold in the tree we're constructing.
 */

struct context {
	const struct context *outer;
	symbol_mt binder;
};

static symbol_mt name_lookup(int index, const struct context *context)
{
	for (assert(index >= 0); index--; assert(context))
		context = context->outer;
	return context->binder;
}

struct shift {
	struct shift *prev;
	int delta, cutoff;
};

static int shift_index(int index, const struct shift *shift)
{
	/*
	 * A shift with delta == 0 marks the end of the line; we
	 * start with one as a terminator but only add shifts when
	 * we link across abstraction depths (so delta > 0).
	 */
	for (assert(shift); shift->delta; shift = shift->prev)
		if (index >= shift->cutoff)
			index += shift->delta;
	return index;
}

static struct term *uncrumble_node(const struct node *node, int cutoff,
				   const struct context *context,
				   struct shift *shift);
static struct term *uncrumble_rl(const struct node *node, int cutoff,
				 const struct context *context,
				 struct shift *shift);

static struct term *uncrumble_slot(unsigned bits, union slot slot,
				   int depth, int cutoff,
				   const struct context *context,
				   struct shift *shift)
{
	assert((bits & ~NODE_LHS_MASK) == 0);

	if (!bits)
		return NULL;
	if (bits & NODE_LHS_BOUND) {
		shift->cutoff = cutoff;
		int shifted = shift_index(slot.index, shift);
		return TermBoundVar(shifted, name_lookup(shifted, context));
	}
	if (bits & NODE_LHS_FREE)
		return slot.term;

	assert(bits & NODE_LHS_SUBST);
	struct node *target = slot.subst;
	assert(target->nref > 0);
	assert(target->depth <= depth);
	if (target->depth < depth) {
		shift->cutoff = cutoff;
		struct shift nextshift = {
			.prev = shift,
			.delta = depth - target->depth,
			.cutoff = 0,
		};
		assert(nextshift.delta);
		return uncrumble_node(target, 0, context, &nextshift);
	}
	return uncrumble_node(target, cutoff, context, shift);
}

static struct term *uncrumble_node(const struct node *node, int cutoff,
				   const struct context *context,
				   struct shift *shift)
{
	if (node->bits == NODE_BITS_ABS) {
		struct node *target = node_abs_body(node);
		assert(!target->prev || target->nref > 0);
		assert(node->depth + 1 == target->depth);
		struct context scope = {
			.outer = context, 
			.binder = node_abs_formal(node),
		};
		return TermAbs(node_abs_formal(node),
			uncrumble_rl(target, cutoff + 1, &scope, shift));
	}

	struct term *lhs = uncrumble_slot(node->bits & NODE_LHS_MASK,
					  node->lhs, node->depth, cutoff,
					  context, shift),
		    *rhs = uncrumble_slot((node->bits & NODE_RHS_MASK) >>
						NODE_LHS_RHS_SHIFT,
					  node->rhs, node->depth, cutoff,
					  context, shift);
	return rhs ? TermApp(lhs, rhs) : lhs;
}

static struct term *uncrumble_rl(const struct node *node, int cutoff,
				 const struct context *context,
				 struct shift *shift)
{
	while (node->prev) node = node->prev;
	return uncrumble_node(node, cutoff, context, shift);
}

struct term *uncrumble(const struct node *node)
{
	assert(node->depth == 0);
	struct shift shift = { .prev = NULL, .delta = 0, .cutoff = 0 };
	return uncrumble_rl(node, 0, NULL, &shift);
}
